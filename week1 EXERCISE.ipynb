{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:27:29.387074700Z",
     "start_time": "2025-07-06T06:27:28.731771200Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.core.display_functions import update_display\n",
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:27:30.736277100Z",
     "start_time": "2025-07-06T06:27:30.720455200Z"
    }
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "#MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_DEEPSEEK='deepseek-chat'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:27:31.881658200Z",
     "start_time": "2025-07-06T06:27:31.866393600Z"
    }
   },
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"DEEPSEEK_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:27:33.466967600Z",
     "start_time": "2025-07-06T06:27:33.452189300Z"
    }
   },
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3f80431d2865d8dd"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-06T06:27:53.036145Z",
     "start_time": "2025-07-06T06:27:35.142308400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, update_display\n",
    "\n",
    "# Get gpt-4o-mini to answer, with streaming\n",
    "client =OpenAI(api_key=api_key,base_url=\"https://api.deepseek.com/v1\")\n",
    "respond = client.chat.completions.create(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=[{\"role\":\"user\",\"content\":question}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "    \n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in respond:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, DisplayHandle\n",
    "from openai import OpenAI\n",
    "\n",
    "# 创建client\n",
    "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "\n",
    "# 提问\n",
    "respond = client.chat.completions.create(\n",
    "    model=MODEL_DEEPSEEK,\n",
    "    messages=[{\"role\": \"user\", \"content\": question}],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# 初始化显示和变量\n",
    "response = \"\"\n",
    "handle = DisplayHandle()\n",
    "handle.display(Markdown(\"\"))\n",
    "\n",
    "# 实时更新Markdown输出\n",
    "for chunk in respond:\n",
    "    delta = chunk.choices[0].delta.content\n",
    "    if delta:\n",
    "        response += delta\n",
    "        cleaned = response.replace(\"```\", \"\").replace(\"markdown\", \"\")\n",
    "        handle.update(Markdown(cleaned))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-06T06:29:15.077980800Z",
     "start_time": "2025-07-06T06:28:54.537735Z"
    }
   },
   "id": "4ac83e37a35898c2"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T09:25:42.396537900Z",
     "start_time": "2025-07-05T09:25:25.262331600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Markdown object>",
      "text/markdown": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\",api_key='ollama')\n",
    "answer = ollama_client.chat.completions.create(\n",
    "    model = MODEL_LLAMA,\n",
    "    messages=[{\"role\":'user',\"content\":question}]\n",
    ")\n",
    "print(answer.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ollama_client = OpenAI(base_url=\"http://localhost:11434/v1\",api_key='ollama')\n",
    "answer = ollama_client.chat.completions.create(\n",
    "    model = MODEL_LLAMA,\n",
    "    messages=[{\"role\":'user',\"content\":question}],\n",
    "    stream=True\n",
    ")\n",
    "response = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in answer:\n",
    "    response += chunk.choices[0].delta.content or ''\n",
    "    response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "    update_display(Markdown(response), display_id=display_handle)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e509b1c79239c737"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
